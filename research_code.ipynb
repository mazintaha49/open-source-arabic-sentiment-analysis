{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "research_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjLw69YdaOVEsXlvDIKkov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mazintaha49/open-source-arabic-sentiment-analysis/blob/main/research_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX4f6qox2hNq"
      },
      "source": [
        "##Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvlX8tBa9SW8",
        "outputId": "62cfec6b-1671-4247-ce5c-db09e616a9bf"
      },
      "source": [
        "# loading dependencies (i.e. importing)\n",
        "\n",
        "\n",
        "# nltk, (multi NLP tasks related  model)\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "# pandas, data frame (rows, colomns) processing model\n",
        "import pandas as pd\n",
        "# numpy, numeric arrays and matrices (rows, colomns) processing model\n",
        "import numpy as np\n",
        "# train_test_split from sklearn model\n",
        "from sklearn.model_selection import train_test_split\n",
        "# re, provides regular expression matching operations\n",
        "import re\n",
        "# string, Common string operations\n",
        "import string\n",
        "# TweetTokenizer, a tokenizer form NLTK model\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "# tokenizer, defining the specifications of the tokenizer, and assigning a name to this specifications\n",
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "# Arabic-Stopwords, (the list of stopwords to be removed)\n",
        "import arabicstopwords.arabicstopwords as stp\n",
        "# stemmer, a arabic stemmer from snowballstemmer model\n",
        "from snowballstemmer import stemmer\n",
        "stemmer_arb = stemmer(\"arabic\")\n",
        "# pyarabic (arabic text processing library)\n",
        "from pyarabic import araby"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivs14qjY2ueG"
      },
      "source": [
        "## Load Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHJh5Nz3AV8K",
        "outputId": "e6d194c8-4782-4bfd-a014-0d4f46f48b0f"
      },
      "source": [
        "# defining a list of the stopwords\n",
        "stp_wd_lis = list(stp.stopwords_list())\n",
        "# printing the length of the list, i.e. stopwords count\n",
        "print(\"stopwords count \\n\", len(stp_wd_lis))\n",
        "# printing the first 5 elements\n",
        "print(\"first 5 elements \\n\", stp_wd_lis[:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stopwords count \n",
            " 13629\n",
            "first 5 elements \n",
            " ['وعداهم', 'جنبنا', 'فباللتين', 'وبماذا', 'وأخونا']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i485ut-O23zR"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zs1CHd_ygN0",
        "outputId": "c9b3a38b-58ac-4983-aedf-4927b85b37db"
      },
      "source": [
        "# load dataset\n",
        "path= 'https://raw.githubusercontent.com/mazintaha49/open-source-arabic-sentiment-analysis/main/dataset.csv'\n",
        "df_text_label= pd.read_csv(path, encoding= 'utf-8-sig')\n",
        "\n",
        "# printing dataset dataframe sample\n",
        "print(df_text_label.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                          tweet_text  label\n",
            "0                               قرفت انتحر عن الدرج    -1.0\n",
            "1                      صدقت يا رب إجعلنا راضين بقدرك    1.0\n",
            "2                            قرف شوهاد شي بخزي عنجد    -1.0\n",
            "3  صحح الخبر . مش تحرير المشتقات النفطية و إنما ت...   -1.0\n",
            "4  قصة جميلة جدا تعكس معنى الايمان و التمسك بالعق...    1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M2JH2ue2_DG"
      },
      "source": [
        "## Process Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTUG8M4szBkh",
        "outputId": "f1f09f15-ce34-4ff4-e760-3d7ff46f78bb"
      },
      "source": [
        "# view dataset info\n",
        "df_text_label.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1991 entries, 0 to 1990\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   tweet_text  1986 non-null   object \n",
            " 1   label       1980 non-null   float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 31.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "YQJofAM317GJ",
        "outputId": "ee75a2fc-5624-446e-e7b3-c3475e506126"
      },
      "source": [
        "# view dataset describtive info\n",
        "df_text_label.describe(include= 'all')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1986</td>\n",
              "      <td>1980.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1966</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>للأسف البعض يعتقد ان المفاعل النووي سيحل مشاكل...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet_text        label\n",
              "count                                                1986  1980.000000\n",
              "unique                                               1966          NaN\n",
              "top     للأسف البعض يعتقد ان المفاعل النووي سيحل مشاكل...          NaN\n",
              "freq                                                    4          NaN\n",
              "mean                                                  NaN     0.000000\n",
              "std                                                   NaN     1.000253\n",
              "min                                                   NaN    -1.000000\n",
              "25%                                                   NaN    -1.000000\n",
              "50%                                                   NaN     0.000000\n",
              "75%                                                   NaN     1.000000\n",
              "max                                                   NaN     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl4NtR6-PySB",
        "outputId": "8251c026-2141-40bc-c79e-c194aed691ef"
      },
      "source": [
        "# view labels distribution\n",
        "print(\"\\n '\\033[4m' initial class distribution '\\033[0m' \\n\\n\", df_text_label.groupby('label')['tweet_text'].nunique())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " '\u001b[4m' initial class distribution '\u001b[0m' \n",
            "\n",
            " label\n",
            "-1.0    968\n",
            " 1.0    987\n",
            "Name: tweet_text, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5Ugw23z2F2i",
        "outputId": "6e49f1cc-5b6b-452a-f799-f1635856a16d"
      },
      "source": [
        "# search for null values within tweet_text column\n",
        "print(df_text_label.tweet_text.isnull().value_counts())\n",
        "\n",
        "# search for null values within label column\n",
        "print(df_text_label.label.isnull().value_counts())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False    1986\n",
            "True        5\n",
            "Name: tweet_text, dtype: int64\n",
            "False    1980\n",
            "True       11\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBJLponE3EIl"
      },
      "source": [
        "# Drop the null values \n",
        "df_text_label.dropna(inplace=True)\n",
        "# Reset index after drop\n",
        "df_text_label.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B8ntEhr31xD",
        "outputId": "521c4426-da6d-4e2e-8146-be1b1f056044"
      },
      "source": [
        "# confirm drop of null values\n",
        "\n",
        "# search for null values within tweet_text column\n",
        "print(df_text_label.tweet_text.isnull().value_counts())\n",
        "\n",
        "# search for null values within label column\n",
        "print(df_text_label.label.isnull().value_counts())\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False    1975\n",
            "Name: tweet_text, dtype: int64\n",
            "False    1975\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKHgZQvq4ES8",
        "outputId": "ae66a199-da77-4ea5-decc-b74c5b21d34d"
      },
      "source": [
        "# check for duplicate values within tweet_text column\n",
        "df_text_label.tweet_text.duplicated().value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    1955\n",
              "True       20\n",
              "Name: tweet_text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbNW2Lh64pmD"
      },
      "source": [
        "# drop duplicate values fro tweet_text column\n",
        "df_text_label.drop_duplicates(subset=['tweet_text'], inplace= True)\n",
        "# Reset index after drop\n",
        "df_text_label.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubXzzIwk5OyB",
        "outputId": "32124f30-2177-4507-c51a-ef3fe7d00fe7"
      },
      "source": [
        "# confirm drop of duplicate values\n",
        "\n",
        "# check for duplicate values within tweet_text column\n",
        "df_text_label.tweet_text.duplicated().value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    1955\n",
              "Name: tweet_text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "BElW0L8k5f2p",
        "outputId": "4c760b69-f993-4d3d-b11e-53473df00830"
      },
      "source": [
        "# view dataset describtive info\n",
        "df_text_label.describe(include= 'all')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1955</td>\n",
              "      <td>1955.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>1955</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>وش التخلف هذا</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.009719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_text        label\n",
              "count              1955  1955.000000\n",
              "unique             1955          NaN\n",
              "top      وش التخلف هذا           NaN\n",
              "freq                  1          NaN\n",
              "mean                NaN     0.009719\n",
              "std                 NaN     1.000209\n",
              "min                 NaN    -1.000000\n",
              "25%                 NaN    -1.000000\n",
              "50%                 NaN     1.000000\n",
              "75%                 NaN     1.000000\n",
              "max                 NaN     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZQZXLEeQMz6",
        "outputId": "2b341865-f0fd-4c3c-8abb-492351d3dd83"
      },
      "source": [
        "# view labels distribution\n",
        "print(\"\\n '\\033[4m' updated class distribution '\\033[0m' \\n\\n\", df_text_label.groupby('label')['tweet_text'].nunique())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " '\u001b[4m' updated class distribution '\u001b[0m' \n",
            "\n",
            " label\n",
            "-1.0    968\n",
            " 1.0    987\n",
            "Name: tweet_text, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT9glxEBqC20"
      },
      "source": [
        "from class distribution, dataset is semi un-biased\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuhd-TXh8VAC"
      },
      "source": [
        "## Tweets Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrVhOZ2kBj_Z"
      },
      "source": [
        "## Count word association"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDp6LpWK8PxK"
      },
      "source": [
        "# tweet processing function\n",
        "\n",
        "def tweet_preprocess(tweet):\n",
        "    \n",
        "    # lower letter\n",
        "    tweet = tweet.lower()\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = \" \".join(re.sub(r\"^RT[\\s]+\", \"\", tweet).split())\n",
        "    # remove urls\n",
        "    tweet = \" \".join(re.sub(\"(http\\S*)|(www\\S*)\", \"\", tweet).split())\n",
        "    # remove only hash # sign from the word\n",
        "    tweet = \" \".join(re.sub(r\"#\", \"\", tweet).split())\n",
        "    # remove mention\n",
        "    tweet = \" \".join(re.sub(\"(@[A-Za-z0-9]+)|(منشن\\S*)\", \"\", tweet).split())\n",
        "    # remove all digit form from word\n",
        "    tweet = str(\"\".join(word for word in tweet for char in word if char not in string.digits).split())\n",
        "    # tokenize tweet\n",
        "    tweet_token = tokenizer.tokenize(tweet)\n",
        "    # remove duplicated letters\n",
        "    tweet_dedup = []\n",
        "    for word in tweet_token:\n",
        "        word_dedup = \"\"\n",
        "        word_str = str(word)\n",
        "        word_dedup = \"\".join(word_str[0])\n",
        "        for i in range (len(word_str)):\n",
        "            if i < (len(word_str) - 1):\n",
        "                init_char = word_str[i]\n",
        "                next_char = word_str[(i+1)]\n",
        "                if next_char != init_char:\n",
        "                    word_dedup += ''.join(next_char)\n",
        "        tweet_dedup.append(word_dedup)\n",
        "    # remove \"tashkeel\", \"tatweel\", and normal \"hamza\"\n",
        "    word_strip = []\n",
        "    for word in tweet_dedup:\n",
        "      word = araby.strip_tashkeel(word)\n",
        "      word = araby.strip_tatweel(word)\n",
        "      word = araby.normalize_hamza(word, method=\"tasheel\")\n",
        "      word_strip.append(word)\n",
        "    # remove punctuation, stopword, and word stemming\n",
        "    tweet_processed = []\n",
        "    for word in word_strip:\n",
        "      # remove punctuation, stopword\n",
        "      if word not in stp_wd_lis and word not in string.punctuation:\n",
        "          # word stemming\n",
        "          tweet_processed.append(stemmer_arb.stemWord(word))\n",
        "\n",
        "    return tweet_processed"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es5WaAd28bil"
      },
      "source": [
        "# word association function\n",
        "\n",
        "def word_association(tweets, labels):\n",
        "    # naming the dictionary to hold association values (i.e. frequencies)\n",
        "    association_dictionary = {}\n",
        "    # defining a set to hold all unique words\n",
        "    uniq_wd_set= set()\n",
        "    for tweet, label in zip(tweets, labels):\n",
        "        for word in tweet_preprocess(tweet):\n",
        "          # adding only words with two or more letters, and less than seven letters\n",
        "          if len(word) <= 7 and len(word) > 2:\n",
        "            # adding word to set (if unique, sets do not accept duplicated values)\n",
        "            uniq_wd_set.add(word)\n",
        "            # defining pair (e.g. (\"جيد\": 1))\n",
        "            pair = (word, label)\n",
        "            if pair in association_dictionary:\n",
        "                # increase count by 1\n",
        "                association_dictionary[pair] += 1\n",
        "            else:\n",
        "                # assign 1 as the association count \n",
        "                association_dictionary[pair] = 1\n",
        "\n",
        "    return association_dictionary  #, #uniq_wd_set"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H-ZiordjewX"
      },
      "source": [
        "## (train / test) split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjbKqM7IjeG8"
      },
      "source": [
        "# spliting dataset as 60% for tarin 40% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_text_label.tweet_text, df_text_label.label, test_size=0.4, shuffle= False)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_hw0FsQDQxU"
      },
      "source": [
        "# building the word association dictionary for train\n",
        "wd_assoc_dict_train = word_association(X_train, y_train)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW1HzeyOD_-b",
        "outputId": "39292de0-04c6-4428-dafa-978104a69584"
      },
      "source": [
        "# view sample of the dictionary keys and values\n",
        "print(\"train \\n\", list(wd_assoc_dict_train.items())[:5])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train \n",
            " [(('قرف', -1.0), 13), (('انتحر', -1.0), 2), (('درج', -1.0), 2), (('صدق', 1.0), 8), (('اجعل', 1.0), 17)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prVNr6ARDOVO"
      },
      "source": [
        "## Perform count refinement (ratio + log)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_kLAr_RDFz6"
      },
      "source": [
        "# count refinement function\n",
        "\n",
        "def count_refinement(tweets, wd_assoc_dict):\n",
        "  # define the new dectionary with refined values\n",
        "  refin_dict = {}\n",
        "  # get word count\n",
        "  for tweet in tweets:\n",
        "    for word in tweet_preprocess(tweet):\n",
        "      # positive count\n",
        "      PN = wd_assoc_dict.get((word, 1.0), 1)\n",
        "      # negative count\n",
        "      NN = wd_assoc_dict.get((word, -1.0), 1)\n",
        "      # total count\n",
        "      TN = PN + NN\n",
        "      # Bayes Probability of word (PW)\n",
        "      PW_p = PN / TN\n",
        "      PW_n = 1 - PW_p     # Probability must add to 1\n",
        "      # Word Ratio (WR), first refinement\n",
        "      WR = PW_p / PW_n\n",
        "      # Log Word Ratio (LWR), second refinement\n",
        "      LWR = np.log(WR)\n",
        "      # update pair value with refined value\n",
        "      refin_dict[word] = LWR\n",
        "\n",
        "  return refin_dict"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qIk2XAKnmz4"
      },
      "source": [
        "# building the refined dictionary\n",
        "refin_dict_train = count_refinement(X_train, wd_assoc_dict_train)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epU2W3nQhaHE",
        "outputId": "d0f887fe-5d68-46cd-9da7-2920a0e0cfda"
      },
      "source": [
        "# view sample of the refined dictionary\n",
        "print(\"train \\n\", list(refin_dict_train.items())[:5])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train \n",
            " [('قرف', -2.5649493574615367), ('انتحر', -0.6931471805599454), ('درج', -0.6931471805599454), ('صدق', 0.9808292530117263), ('يا', 0.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n7LGNhipeRK"
      },
      "source": [
        "## Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7obyHSBoe4z"
      },
      "source": [
        "# making predictions function\n",
        "\n",
        "def make_prediction(tweets, refin_dict):\n",
        "\n",
        "  # define the prediction list\n",
        "  pred_lis = []\n",
        "  # define the LWR sum value holder list\n",
        "  LWR_sum_lis = []\n",
        "  for tweet in tweets:\n",
        "    #define the LWR sum value holder\n",
        "    LWR_sum = 0\n",
        "    for word in tweet_preprocess(tweet):\n",
        "      # get word LWR\n",
        "      wd_LWR = refin_dict.get(word, 0)\n",
        "      # add word LWR to LWR_sum (for tweet LWR)\n",
        "      LWR_sum += wd_LWR\n",
        "    # add LWR_sum to LWR_sum_lis\n",
        "    LWR_sum_lis.append(LWR_sum)\n",
        "  \n",
        "  # make prediction\n",
        "  for LWR_sum in LWR_sum_lis:\n",
        "    if LWR_sum > 0.0:\n",
        "      pred_lis.append(1.0)\n",
        "    else:\n",
        "      pred_lis.append(-1.0)\n",
        "\n",
        "  return pred_lis\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbPHfiVtsNV4"
      },
      "source": [
        "pred_lis = make_prediction(X_test, refin_dict_train)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngk72gSusXNu",
        "outputId": "7e1df273-09ab-4e1d-fefe-212b4ae05624"
      },
      "source": [
        "# view sample of the prediction list\n",
        "print(pred_lis[:5])\n",
        "# compare label list length prediction list lenght\n",
        "print(len(y_test))\n",
        "print(len(pred_lis))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.0, 1.0, -1.0, -1.0, -1.0]\n",
            "782\n",
            "782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ_RrblTshz6"
      },
      "source": [
        "## Calculate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a91fpXBtsf4Q"
      },
      "source": [
        "# calculate accuracy function\n",
        "\n",
        "def calc_acc(labels, pred_lis):\n",
        "\n",
        "  # define error counter\n",
        "  error = 0\n",
        "  for label, pred_label in zip(labels, pred_lis):\n",
        "    # check for un-correct prediction\n",
        "    if label != pred_label:\n",
        "      error += 1\n",
        "  \n",
        "  # calculate accuracy\n",
        "  acc = 1 - (error / (len(labels)))\n",
        "\n",
        "  return acc"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPSobqTasmC0"
      },
      "source": [
        "acc = calc_acc(y_test, pred_lis)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqh94t30uJkD"
      },
      "source": [
        "## Display results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXximOijuLEl",
        "outputId": "f4aed502-a6d1-4f5d-c1e1-dc8237381d2d"
      },
      "source": [
        "# predictions accuracy result desplay\n",
        "print(\"\\n '\\033[4m' Naive Bayes accuracy '\\033[0m' \\n\\n\", np.round((acc*100),2), \"%\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " '\u001b[4m' Naive Bayes accuracy '\u001b[0m' \n",
            "\n",
            " 83.25 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YQTDLhfvSLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01fb2e67-e85e-4f94-d451-1c0136c3c18c"
      },
      "source": [
        "# classification classes distribution\n",
        "from collections import Counter\n",
        "\n",
        "label_pred = Counter(pred_lis).items()\n",
        "print(\"\\n '\\033[4m' classification classes distribution '\\033[0m' \\n\\n\", label_pred)\n",
        "# compared to original classes\n",
        "label_orig = Counter(y_test).items()\n",
        "print(\"\\n '\\033[4m' original classes '\\033[0m' \\n\\n\", label_orig)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " '\u001b[4m' classification classes distribution '\u001b[0m' \n",
            "\n",
            " dict_items([(-1.0, 416), (1.0, 366)])\n",
            "\n",
            " '\u001b[4m' original classes '\u001b[0m' \n",
            "\n",
            " dict_items([(1.0, 401), (-1.0, 381)])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}